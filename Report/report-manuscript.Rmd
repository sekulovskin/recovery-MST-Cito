---
title: "**Internship Report**: ***Recovery of Early Mistakes in Multistage Tests***"
date: "10.1.2022 - 18.2.2022"
author: Nikola Sekulovski
output: 
  html_document:
    toc: true
    toc_float: true
bibliography: ["ref.bib"]
csl: apa-no-doi-no-issue.csl
link-citations: TRUE
---
<style>
body {
text-align: justify}
</style>


```{r libraries, include=FALSE}
library(tidyverse)
library(Hmisc)
library(gtsummary)
library(knitr) 
library(ggpubr)
library(lmtest)
library(car)
library(foreign)
library(haven)
library(emmeans)
library(rstatix)
source("C:/Users/nikol/Desktop/MSc MSBBSS/Year-2_2021-2022/Internship/repo/mst/simulation/ref-score&classification-functions.R")
options(knitr.kable.NA = '/')
```

<center> <h1>**Introduction**</h1> </center>
 
*Multistage tests* (MSTs), are said to be "the best of both worlds" when compared to the traditional *Linear Tests* (LTs) on the one hand, and *Computerized Adaptive Tests* (CATs) on the other. They allow for the adaptation of the difficulty of the items, based on the level of proficiency, without many of the shortcomings that follow when using completely adaptive tests (such as CAT). Briefly, many of the problems that CATs face, such as the lack of control over item ordering, not being easily applicable to essay items, no possibility of reviewing, difficulty of programming, etc, ar compensated for when using MST's. Multistage tests can be seen as a series of small sequential batches of items (called *modules*), where, based on the proficiency estimate in one module, an appropriately difficult following module is administered. Every specific combination of modules can be seen as a separate booklet, which implies that different students (with varying levels of proficiency) can follow different paths (which can be seen as booklets). For more details on MSTs, see, for example @yan2016computerized pp 3-20. 
The particular MST that is studied here is called **ACET** (*Dutch*: Adaptive Centrale Eindtoets), which was developed by [Cito](https://www.cito.com/) for the classification of primary education students on different levels (also called classes) of secondary education. **ACET** is comprised of  three separate MST's for measuring *Reading (Lezen)*, *Mathematics (Rekenen)* and *Language proficiency (Taal)*, and a linear test for *Writing (Schrijven)* (throughout this report the Dutch names for the subjects are used). The estomated latent abilities are translated into reference scores and the final score of *ACET* is calculated as a composite of the reference scores on the four subjects (relevant for the second simulation where the focus is on classification errors). The MST design for the all three subjects is presented below.
  
```{r ACET, out.width = "70%", fig.align = 'center', echo=FALSE}
include_graphics("ACET.jpg")
``` 
Knowing how MSTs (and adaptive tests in general) work, it is only logical to ask: how fair are these tests when estimating the final ability of the students? More specifically, what happens when, for example, a highly proficient student makes mistakes in the early stages of the MST, and as a result is routed thorough a easier path? In other words: *to what extent can students "recover" from mistakes made in an earlier stage(s) and still reach an estimate close to their true ability?* This is the research question that is tackled in the work presented in this report, in an effort to answer this issue specifically for *ACET*. 
**ACET** consists of multiple versions for each module on all three subjects. In order to keep the simulation as simple as possible,  a special version of the MST developed for hearing impaired students will be used, which only contains one version per module.  Throughout this report the terms ability, proficiency and $\theta$ (which is the Greek symbol used in [IRT](https://en.wikipedia.org/wiki/Item_response_theory) to represent the latent ability) are used interchangeably. In striving to answer the research question, two simulations studies were conducted.

This report is divided as follows. In the next section the first (initial) simulation, undertaken to explore how these particular MSTs function when we "know" the true ability of the students is presented and results from initial statistical analyses are discussed. Afterwards, the number of errors in Module A and in Day 1 are calculated and visual representation of the difference between the true and re-estimated ability are given for all three subjects. Also, the number of different paths, with a special focus on the students located on the extremes of the latent ability distribution is presented and discussed. In the end of this section, in a small statistical "experiment" is explored whether there are significant differences in the difference between the true and the re-estimated proficiency between the three subjects when controlling for different excoriates. In the section afterwards, using the observed data from ACET 2021, we repeat the simulation using the ....(finish this after finishing the actual sections).
All the code used to obtain the results presented in this report is openly available on [GitHub](https://github.com/sekulovskin/recovery-MST-Cito). Note, due to the nature of the simulations (more specifically the way the multiple MST responses are generated), exact replications are not possible (even when using the same random seed), thus the results might slightly vary. However, the simulations were repeated many times, and roughly the same results were observed.

  <center> <h1>**Initial Analyses (Simulation 1)**</h1> </center>

## Outline of the simulation study

```{r data from sim 1, include=FALSE}
load("C:/Users/nikol/Desktop/MSc MSBBSS/Year-2_2021-2022/Internship/repo/mst/simulation/initial.simulated.responses.RData")
```
   
 In this section, the results from the analyses based on the first simulation will be presented. Using the observed distributions of the abilities from the 2021 administration of **ACET** and adding the theoretically possible extreme values on the edges (which otherwise weren't likely to be simulated when using the observed distributions), 200  $\theta$ values for each subject were generated, and treated as the true abilities of 200 artificial students. A summary of these ability distributions is presented below. 
 
```{r summary of thetas, echo=FALSE, fig.cap= "True ability distributions based on the observed results from ACET 2021"}
thetas <- data.frame(true.theta_L, true.theta_R, true.theta_T)
names(thetas) <- c("Lezen", "Rekenen", "Taal")
tbl_summary(thetas, statistic = list(all_continuous() ~ "{mean} ({sd}) [{min}, {max}]"))
```

 Afterwards, **ACET's** test design, routing rules and the item parameters, for each subject, were used to generate a 1000 MST responses for each artificial student (i.e., for each true $\theta$). These responses were simulated using the `sim_mst` function from the package `dexterMST` [@dextermst], which simulates data from an Extended Nominal Response Model. Afterwards, using the `ability` function from the package `dexter` [@dexter], re-estimates of the true ability were obtained with Weighted Likelihood Estimation (WLE) for all 1000 simulated responses for the 200 students for each of the three subjects (resulting in 200000 different response patterns for each subject). This plethora of responses for each level of ability allows to, separately,  explore how the ability estimate for each of the three subjects changes when certain factors, such as the number of mistakes in module A, the number of mistakes in Day 1 and different MST paths are varied. 

## Welch tests

 In order to preliminary inspect whether different patterns produced by the multiple simulated responses for each level of the true ability lead to differences between the true and the re-estimated $\theta$ simple [Welch's Tests](https://en.wikipedia.org/wiki/Welch%27s_t-test) were executed comparing each true $\theta$ and the mean of the re-estimated $\theta's$  for each subject. Briefly, the goal here is to inspect whether there is a *statistically significant* difference between the true and the average of the re-estimated $\theta's$ for each level of the true ability. However, this is done out of pure exploratory reasons and the p-values are always "taken with a grain of salt", since they can be quite misleading, especially when having a big sample size (which in this case is a 1000 - the number of simulations), the interested reader is refereed to @cohen1994earth for further elaborations the issues with standard Null Hypothesis Testing. Since we are dealing with a "large enough" sample size we will use the value of $\alpha = .01$ as a cutoff for whether a mean difference is significant.
 
 <center> <h4>Lezen</h4> </center>

```{r p-values Lezen, echo=FALSE, fig.cap= "Mean, SD, and 98% interval of the p-values for Lezen"}
lezen_welch <- lapply(students_abilities_L, function(x){t.test(x[,4],x[,5])})
p <- data.frame()
  for(i in 1:length(true.theta_L)){
    p[i,1] <- lezen_welch[[i]]$p.value 
  }
names(p) <- "p values"
tbl_summary(p, statistic = list(all_continuous() ~ "{mean} ({sd}) [{p1}, {p99}], "))
```

As can be seen from the results presented in the table above, the mean p-value is quite high (0.48) however the lower bound of the 98% interval contains the value of .01, indicating that there are some instances for which true $\theta's$  are significantly different from their respective average re-estimated counterparts. 

```{r include=FALSE}
which(p$`p values` <= 0.01)
true.theta_L[c(1,   2,   3,   4,   5,   6,   7,   8,  41,  59,  78, 162, 166, 196, 197, 198, 199, 200)]
transform.ref.score.lezen(true.theta_L[c(1,   2,   3,   4,   5,   6,   7,   8,  41,  59,  78, 162, 166, 196, 197, 198, 199, 200)])
```
More specifically, the observed significant differences were for $\theta$ values of  -2.54, -1.8, -1.5, -1.3, -1.2, -1, -0.9, -0.8, -0.007,  0.08,  0.13, 0.4,  0.43,  1.2,  1.4, 1.7, 2.2 and 3.4, which correspond to reference Lazen scores of  0,  2,  3,  4,  5,  7,  9, 11, 46, 51, 54, 66, 66, 80, 81, 82, 83 and 84, respectively. This indicates that most of the mismatches between the true and the re-estimated ability tend to be on the extreme, however, there are also a few values in the middle of the ability range. 

 <center> <h4>Rekenen</h4> </center>

```{r p-values Rekenen, echo=FALSE, fig.cap= "Mean, SD, and 98% interval of the p-values for Rekenen"}
rekenen_welch <- lapply(students_abilities_R, function(x){t.test(x[,4],x[,5])})
p <- data.frame()
  for(i in 1:length(true.theta_R)){
    p[i,1] <- rekenen_welch[[i]]$p.value 
  }
names(p) <- "p values"
tbl_summary(p, statistic = list(all_continuous() ~ "{mean} ({sd}) [{p1}, {p99}], "))
```
The mean p-value for Rekenen is higher than for Lazen, roughly indicating less problems with high difference, however the 98% interval still contains the cutoff of 0.01.

```{r include=FALSE}
which(p$`p values` <= 0.01)   
true.theta_R[c( 1,   2,   3,  22,  45,  81,  89,  98, 141, 187, 200)]
transform.ref.score.rekenen(true.theta_R[c(1,   2,   3,  22,  45,  81,  89,  98, 141, 187, 200)])
```
In this case significant differences were found for theta values -1.97, -1.43, -1.17, -0.16, 0.042,  0.21,  0.23,  0.27, 0.5,  0.93 and 1.85 corresponding to reference Rekenen scores of 1,  2,  3, 16, 21, 25, 25, 27, 31, 37 and 40 respectively. 

 <center> <h4>Taal</h4> </center>

```{r p-values Taal, echo=FALSE, fig.cap= "Mean, SD, and 98% interval of the p-values for Taal"}
taal_welch <- lapply(students_abilities_T, function(x){t.test(x[,4],x[,5])})
p <- data.frame()
  for(i in 1:length(true.theta_T)){
    p[i,1] <- taal_welch[[i]]$p.value 
  }
names(p) <- "p values"
tbl_summary(p, statistic = list(all_continuous() ~ "{mean} ({sd}) [{p1}, {p99}], "))
```

The mean p-value for Taal is somewhere in between Rekenen and Lezen.
```{r include=FALSE}
which(p$`p values` <= 0.01)   #
true.theta_T[c(1,   2,  35,  40,  50,  80, 114, 126, 151, 173, 197, 198, 199, 200)]
transform.ref.score.taal(true.theta_R[c(1,   2,  35,  40,  50,  80, 114, 126, 151, 173, 197, 198, 199, 200)])
```


Here significant differences were found for $\theta$ values -1.7, -1.3, -0.03,  0.012,  0.07,  0.18,  0.304, 0.36,  0.46, 0.6, 1.4, 1.6,  1.8 and  2.12 corresponding to reference Taal scores of 0,  1, 35, 36, 42, 49, 55, 58, 61, 64, 68, 69, 70 and 70 respectively.
  
**Conclusion:** Based on the presented preliminary analyses, it can be seen that, when we do not control for any variables, and just inspect whether there is a difference between the true and the average of the re-estimated $\theta's$ for each true ability: 
 
 - *Lezen* has the highest magnitude of significant results (having the lowest mean p-value), with 9%  of the true abilities significantly differing from their mean re-estimated counterparts (with most being on the extremes of the latent ability distribution);
 
 - *Rekenen* has the the smallest magnitude of significant results (having the highest mean p-value) with around 5.5 % of the  of the true abilities significantly differing from their mean re-estimated counterparts. However, in this case mismatches were slightly more evenly spread out through the whole latent ability continuum;
 
 - *Taal* is somewhere in the middle both in terms of the magnitude of p-values and also in terms of the percentage of $\theta$ values  significantly differing from their mean re-estimated, which in this case was 7%. 
 
Based on this first basic rudimentary analyses on the simulates MST responses, we can conclude that mismatches between the true and the re-estimated proficiency tend to appear, especially for the subject Lezen. These results give reason to continue to explore why this is the case by considering different aspects of the MST, which is done in the sections that follow.


## Number of early mistakes 

Since it is in the inherent nature of an MST  that the the performance in the early (or even the first) module is crucial in deciding in which module will a student be routed in the following stage (see, [Introduction section](# **Introduction**)) it is important to consider students responses on the early stages. Thus, `R` scripts that calculate the number of mistakes in Module A *and* the number of mistakes on Day 1 were written and used both in this simulation and in the one presented in the next section. In *ACET* students are either awarded the maximum number of points or no points, thus a mistake is defined as a score of zero on a particular item.

Here the repeated re-estimates for the "students" that showed significant differences in the [initial analysis](## Initial analyses) were separated with respect to the number of mistakes in module A in order to see whether the observed significant differences can be attributed to the number of errors. No statistical significance tests were implemented in this situation since the number of replications on different errors (mistake levels) is highly variable, which would've resulted in p-values that make little sense. Thus, a tabular representation of these results for each subject are presented below. Here the mean number of mistakes for each number of mistakes on each of the significant proficiency found in the first analyses are presented (for all three subjects). Moreover, plots of the same results are available in the [Appendix](#*Appendix*). These analyses will not be repeated for the number of mistakes on Day 1, since, as can be seen from the **ACTET** MST design presented in the introduction, these represent the sum of mistakes in stages 1 2 and 3, which means that separating on a wide range of number is not very insightful. However, the number of mistakes on Day 1 is used as a covariate in the main statistical analysis presented at the end of this section. 


### Mistakes in Module A

<center> <h4>Lezen</h4> </center>
```{r echo=FALSE}
mistakes.modA.lezen <- read.csv("mistakes.modA.lezen.table.csv")
names(mistakes.modA.lezen) <- c("0", "1", "2", "3", "4", "5", "6", "Average re-restimated theta", "True theta")
mistakes.modA.lezen[mistakes.modA.lezen == 0] <- NA
kable(round(mistakes.modA.lezen, 4))
```

It is evident that for the extreme ability values, high mismatches tend to appear, regardless of the number of mistakes. In other words, high discrepancies between the true and re-estimated $\theta$ appear even when students make the perfect score (6 for low achieving students and 0 for high achieving students). For example, the student with a true ability of -2.54 has an estimated ability of -1.97 even when incorrectly scoring all six items in the first module. A similar situation can be observed with the students having true abilities of 3.4, 2.2 and 1.7. For the medium achieving students there tend to be smaller discrepancies, especially when approaching the appropriate number of mistakes for that level of proficiency, though, average discrepancies of 0.1 units on the latent ability scale can still be observed. The fluctuation of the re-estimates as a function of the number of mistakes in module A is quite mild, indicating that these medium proficient students are not as sensitive to the number of mistakes in module A as high proficient students.

<center> <h4>Rekenen</h4> </center>
```{r echo=FALSE}
mistakes.modA.rekenen <- read.csv("mistakes.modA.rekenen.table.csv")
names(mistakes.modA.rekenen) <- c("0", "1", "2", "3", "4", "5","Average re-restimated theta", "True theta")
mistakes.modA.rekenen[mistakes.modA.rekenen == 0] <- NA
kable(round(mistakes.modA.rekenen, 4))
```

The most desirable situation can again be observed with the subject Rekenen, where even on the extremes of the latent ability continuum, the discrepancies between the true and the re-estimated abilities  tend to be significantly lower when compared to Lezen. The fact that differences between the true and the re-restimated $\theta$ when having the perfect score are still observed for these extreme values, is not an inherint issue only to MST, but it is also connected to the test information, In other words, the items (and consequently the test) does not posses enough information to accurately capture the abilities on the extremes, which is beyond the scope of this project. When we look at the medium proficient students we can see that there aren;t many big fluctuations, however, as the number of mistakes becomes too low or too high differences of around 0.1 units can still be observed. However, when this is translated into reference scores, it doesn't impose a much of a problem (further elaborated in Simulation 2). 

<center> <h4>Taal</h4> </center>
```{r echo=FALSE}
mistakes.modA.taal <- read.csv("mistakes.modA.taal.table.csv")
names(mistakes.modA.taal) <- c("0", "1", "2", "3", "4", "5","Average re-restimated theta", "True theta")
mistakes.modA.taal[mistakes.modA.taal == 0] <- NA
kable(round(mistakes.modA.taal, 4))
```

The situation with Taal is quite similar to the one with Lezen and high mistmatches are present on the edges of the distribution. The fact discrepancies with a higher magnitude were observed for Lezen than for Taal, is the fact that Lezen has a wider range than taal (see the first table, where the distribution of hte true abilities are given).

It is important to note that medium proficient students, when scoring a perfect score tend to be over/under estimated by around 0.1 units on the latent ability scale. Thus, proving once more, that most of the difficulties apprear on the edges of the ability.

 
## Number of paths per subject

It is also important to inspect whether the large discrepancies between the true and re-estimated latent ability,  can be attributed to taking different paths trough the MST for the latent abilities located on the edges of the distribution. Since it is rare to expect that those students would take another path than the "perfect" one^[A perfect path is a completely difficult or completely easy path such as A-C-F-I and A-B-D-G.] For this purpose the high and low true $\theta's$ that showed significant differences in the initial analysis are used, and inspected whether they took more than one path (for each of the three subjects). Afterwards, the mean $\theta$ re-estimates are calculated for each path separately in order to see whether taking one path over another can (partly) explain the ability discrepancy observed in the first analysis.

 <center> <h4>Lezen</h1> </center>

```{r echo=FALSE}
paths.lezen <- read.csv("paths.lezen.csv")
names(paths.lezen) <- c("Path", "Average re-estimated theta", "True theta")
kable(paths.lezen, digits = 4)
```
Only two students on the positive extreme had followed more than one path. The results presented in the table above show that when a highly proficient student makes a mistake in Module A of the Lezen MST and is routed to easier Module B instead to the more difficult Module C in the second stage, big ability discrepancies tend to appear. For example, the student with a true $\theta$ of 1.2 has an average re-estimated $\theta$ of 1.18 when following the perfect route (i.e., A-C-F-I), however, that re-estimate falls down ~ 0.9 when taking the route A-B-F-I. A similar situation is observed with the true latent ability of 1.4. These results clearly indicate that when a student makes mistakes in Module A of the Lezen MST, and is routed to the easier Module B in the second stage, even if he/she manages to continue on the difficult route in stages 3 and 4, the final estimate of ability differs quite a lot compared to when being routed to Module C in the second stage. This should be kept in mid when administering the Lezen MST, some recommendations are given in the [Conslusion section](# **Conclusion**).

 <center> <h4>Rekenen</h1> </center>

```{r echo=FALSE}
paths.rekenen <- read.csv("paths.rekenen.csv")
names(paths.rekenen) <- c("Path", "Average re-estimated theta", "True theta")
kable(paths.rekenen, digits = 4)
```
Only one student on the positive extreme followed more than one path for the repeated simulations. Based on the results presented in the table above, it is obvious that students can more easily recover from mistakes made in Module A (i.e., being routed to Module B instead to module C in the second stage, and then going back to the difficult Module E), than they can recover from mistakes in the second or the third stage (see paths A-C-F-H, A-C-E-H). This is a desirable charachetristic and is one more reason why lower discrepancies tend to appear in Rekenen.
 <center> <h4>Taal</h1> </center>

```{r echo=FALSE}
paths.taal <- read.csv("paths.taal.csv")
names(paths.taal) <- c("Path", "Average re-estimated theta", "True theta")
kable(paths.taal, digits = 4)
```

It can be seen that with Taal more mistmathces tend to appear when the non-perfect path is followed relative to Rekenen. However,possibilities for recovery of eraly mistakes are not completely impossible (see, path A-B-E-I).

It should be noted that some of the the differences can be attributed to the fact that we are not dealing with the same level of ability in the different courses, furthermore the weights and even the number of items are not the same for all three courses. Thus, in this analysis all three courses should be considered separately.

## Main Statistical Analysis 

By now it is already evident the most of the problems concerning the recovery from early mistakes are present in the Lezen MST. However, due to the dimensionality of the research question, it is very possible that certain differences might be hidden due to confounding. Thus, in an effort to inspect whether significant differences in the ability discrepancy (between the true and re-estimated abilities) for the three courses are present, when controlling for certain covariates, an [Aalysis of Covariance](https://en.wikipedia.org/wiki/Analysis_of_covariance) was performed on the simulated data, with the following variables:

 - **Dependant variable:**: The average absolute difference the true and re-estimated thetas for each level of true ability (since the focus of the analysis is on the magnitude of the discrepancy between the true and re-estimated thetas, and not in the direction of that difference);
 - **Indepdentend (factor) varable:** The subjects, having three levels (Lezen, Taal and Rekenen);
 - **Covariates:**
    - Average number of mistakes in Module A
    - Average number of mistakes in Day 1
    - Number of paths for each different theta
    - Weights of the items in the first module

### The data

The summary statistics for the outcome variable and the covariates for each class are presented below. 
 Taal has the highest mean average theta discrepancy, shortly followed by Lezen (they differ in 0.001 units), while Rekenen has the lowest mean average theta discrepancy. It should be mentioned that the difference in the mean  average number of errors in Module A betwen Lezen on the one hand and Rekenen and Taal on the other is due to the fact that Module A for the former containts 6 items in total, whereas the latter contain 5 each. We can see that the highest mean average number of errors is present in Rekenen, and the most number of paths are present in Taal.
 
```{r echo=FALSE, message=FALSE, warning=FALSE}
data <- read_sav("experiment_data.sav")
data$subject <- factor(data$subject, labels = c("Lezen", "Rekenen", "Taal"))
data2 <- data
names(data2) <- c("Avg. theta difference", "Avg. n of errors in Mod A", "Avg. errors in Day 1", "Number of paths", "Subject")

data2 %>%
  group_by(`Subject`) %>%
  select(`Avg. theta difference`, `Avg. n of errors in Mod A`, `Avg. errors in Day 1`, `Number of paths`) %>%
  summarise_all(funs(mean)) %>%
  kable(digits = 4)


```

Below the relationship between the outcome variable and each covariate is displayed. Of course, as expected due to the nature of the dependent variable 
```{r echo=FALSE, fig.align='center'}
data$subject <- as.factor(data$subject)
scatter <- ggplot(data, aes(avg.error.modA, avg.theta.diff, colour=subject))  
A <- scatter + geom_point() +
   theme_classic() + theme(legend.position="none") + 
  labs(y = "Avg. theta difference",x = "Avg errors in Module A")

# For average mistakes in day 1
scatter <- ggplot(data, aes(avg.error.Day1, avg.theta.diff, colour=subject))  
B <- scatter + geom_point() + 
  theme_classic() + theme(legend.position="") + 
  labs(y = "Avg. theta difference", x ="Avg errors in Day 1")

# For number of paths
scatter <- ggplot(data, aes(n.paths, avg.theta.diff, colour=subject))  
C <- scatter + geom_point() +
  theme_classic() + 
  labs(y = "Avg. theta difference", x = "Number of paths")

#Combine
ggarrange(A, B, C,
          labels = c("", "", ""),
          ncol = 2, nrow = 2)
```

### Assumptions

There are many option in tackling issues regarding the violations of assumptions in ANCOVA (and in linear models in general). For example, one can use so-called [Generalized Linear Models](https://en.wikipedia.org/wiki/Generalized_linear_model), [nonparamteric](https://en.wikipedia.org/wiki/Nonparametric_statistics) alternatives, [robust analyses](https://en.wikipedia.org/wiki/Robust_statistics) or account for the violations directly. Since the aim of this work is to explore and clearly communicate certain issues, the last approach will be taken. Since the aim of this analysis is to illustrate as simply as possible whether there are differences between the three courses in the difference between the true and estimated ability after controlling for the above-mentioned covariates, it is best to stick with the most simple and straightforward analysis, of course, while always taking the p-values with "a grain of salt", since certain violations of the assumptions may decrease the estimates of the SE and consequently influence the p-values. However, in the results that follow the obtained p-values were very low, inficating that there is an effect, even if some of the (non accounted for violations) made them smaller than they truly are. In other words if violations of the assumptions are an expected part of the analysis and if they are clearly communicated then one can proceed to *cautiously* interpret the results (for more elaborations, see, @field2012discovering, Chapter 11).


#### Normality
When performing an ANCOVA and related analyses, one assumption that is often the first to be checked, is whether the frequency distribution of the dependent variable (approximately) follows a normal distribution. On the left hand side of the plot below, a histogram of the observed, average theta differences (for all three courses together) is presented. It is clear, and expected, that most of the observations are accumulated around 0, followed by a sharp decrease, which is a clear sign of non-normality. One suggested solution, that is often taken, is to [tranform](https://en.wikipedia.org/wiki/Data_transformation_(statistics)) the outcome variable, which makes highly skewed data more normal, while at the same time keeping the internal relationship of the data points the same. The figure on the right hand side shows the inverse of the  outcome variable. Even though it is now slightly negativelu skewed, based on current statistical literature, this assumption doesn't expect the frequency of the outcome needs to *perfectly* follow a normal distribution but needs to not *seriously* deviate from normality, this is often confused with the assumption that the residuals need to be normally distributed around zero (see [this](https://towardsdatascience.com/is-normal-distribution-necessary-in-regression-how-to-track-and-fix-it-494105bc50dd) resource for further information). 

```{r echo=FALSE, fig.align='center', message=FALSE, warning=FALSE}
data <- read_sav("experiment_data.sav")
A <- ggplot(data, aes(x = avg.theta.diff)) +
   geom_histogram(fill = "black") +
  theme_classic() +
  labs(title  = "Average theta difference" , x = "", y = "")
B <- ggplot(data, aes(x = 1/avg.theta.diff)) +
  geom_histogram(fill = "black") +
  theme_classic() +
  labs(title  = "Inverse of the Average theta difference", x = "", y = "")

ggarrange(A, B,
          labels = c("", ""),
          ncol = 2, nrow = 1)
```

#### Outliers
Another assumption is the presence of outliers. As it had been discussed above, there tend to be big discrepancies between the true and average re-estimated abilities when we have extreme (positive and negative) values for the true theta, which would represent outlines in this analyses. However, keeping these values in is a very important aspect of what is aimed to be achieved. Since the main objective is to see whether we still find differences between the groups even after controlling for the covariates.

#### Equality of variance

The [Levene's test](https://en.wikipedia.org/wiki/Levene%27s_test) for equality of variances F(2, 597) = 2.06, p = .13, meaning that  null hypothesis which states that the variances in the outcome variable between the three subjects are the same, cannot be rejected. In other words, this assumption has been met. 
```{r echo=FALSE}
levenes_test <- leveneTest(avg.theta.diff ~ factor(subject), data)
kable(levenes_test)
```

#### Homogeneity of regression slopes
The assumption of homogeneity of regression slopes is clearly violated, since thee regression line for Lezen crosses the ones for Taal and Rekenen in for all three covariates (see the plot in the [Appendix](#Appendix). However, since it was expected that this would happen due to the nature of the data, it is proceeded with interpreting the results.

### Results 

For both models the [Type III Sum of Squares](https://towardsdatascience.com/anovas-three-types-of-estimating-sums-of-squares-don-t-make-the-wrong-choice-91107c77a27a) are observed.

#### ANOVA

First a regular Analysis of variance was performed to see whether significant differences between the three classes on the inverse of the average theta ability difference were present. As can be seen from the table below there is a significant difference between at least two of the three classes in the inverse of the average ability difference, F(2, 597) = 63.66, p < .0001. 

```{r echo=FALSE}
anova <- aov(1/avg.theta.diff ~ subject, data = data)
anova <- anova(anova)
kable(anova)
```


#### ANCOVA

In order to test whether when "equalizing" the average ability differences on covariates such as the number of mistakes and number of different paths taken in the MST, two ANCOVA models were fitted. The first contained all three covariates and in the second the average number of mistakes in module A was taken out, the reasoning behind this was that the number of mistakes in Day 1 contains the number of Mistakes in Module A, and thus fitting a more complex model did not add any values to the analyses (the difference and resulting F-test value was the same).

As can be seen in the table below all three covariates have a significant relationship with the dependent variable. Furthermore, the difference between the groups is still significant (F(1, 596) = 268.82, p < .0001). This means that there is a significant difference between the means of the *inverse* average ability discrepancies, when controlling for the number of mistakes in day 1 and the number of paths taken in the MST for the repeated simulations. 

```{r echo=FALSE}
ancova <- aov(1/avg.theta.diff ~ avg.error.Day1  +  n.paths + subject, data = data)
ancova <- Anova(ancova, type = "III")
kable(ancova)
```


#### Post hoc tests

Now since we know that there is a significant difference between at least two of the three classes, it is time to incpect where are these differences. For this [post hoc tests](https://en.wikipedia.org/wiki/Post_hoc_analysis) with a *Bonferroni correction* for the alpha value were applied.

```{r echo=FALSE}
post_hoc <- emmeans_test(1/avg.theta.diff ~ subject, covariate = c(avg.error.Day1, n.paths),
                         p.adjust.method = "bonferroni", data = data) 

post_hoc[1,3] <- "Lezen"
post_hoc[2,3] <- "Lezen"
post_hoc[3,3] <- "Rekenen"
post_hoc[1,4] <- "Rekenen"
post_hoc[2,4] <- "Taal"
post_hoc[3,4] <- "Taal"
kable(post_hoc[, -c(1,2,7)], digits = 4)

rm(list=ls()) 
```

As can be seen from the table above, significant differences for the means of the *inverse* average ability discrepancies, when controlling for the number of mistakes in day 1 and the number of paths, appear between the subjects Taal and Lezen and Taal and Rekenen. The main conclusion from this analysis, which is connected to what was observed in the previous sections, is that the Rekenen MST, by far, produces the smallest discrepancies between the true and the estimated ability. Furthermore these results *hint* that *when controlling for important factors* in the MST, the lead with respect to the highet discrepances is taken on by Taal. However, this second  observation should be taken with caution due to all the aforementioned issues regarding the assumptions of this particular analysis and also the problems with Null Hypothesis Significance Testing in general. Additionally, another aspect that might cast doubnt on this last observation is are covariates that are not included in the analysis above. For example, one such covariate is the average weights of the items in Module A, with Lezen having the highest value (5.3) and Taal the lowest (3.2), with Rekenen in the middle with 4. 

It should be noted that due to the non-linear relationships between the dependent variable and the predictors (see, plots) a quadratic term was added for each of the covariates, and no differences in the results were observed whatsoever. Thus, it was decided to continue with the more simple analysis.

<center> <h1>**Classification Errors (Simulation 2)**</h1> </center>

## Introduction

The aim of [Simulation 1]() was to look at how the MST's of the three subjects react and differ from each other when considering different aspects of the test design. The aim of this simulation on the other hand, is to look at all the three tests together, and hopefully try to figure out how the number of mistakes made in Modules A in all three MST subjects, relates to the classification in classes of secondary education and, furthermore,  derive certain threshold values above which mislcassifications tend to appear. For this simulation, the observed ability estimates (including the subject Schrijven), final test scores and associated classifications in secondary education for all students that participated in **ACET 2021**, were used. 
The average ability estimate for each subject was used to create the typical "student" for each of the 6 classes of secondary education. Afterwards, these true abilities were used to generate a 1000 MST responses for each perfect student, resulting in 6000 different MST patterns per subject. Afterwards, functions that transform the ability estimates into reference scores, based on the rules used for **ACET** (see the table below), were programmed for all four subjects. Additionally a function that classifies students in one of the 6 classes of secondary education based on their **total test score** was programmed. The test score is derived  using a linear function of the reference scores for each subject, The weights in the linear function are bsed on long-term monitoring of students in the first three years of secondary education. The linear function is presented in the [Appendix]() (note that Rekenen is the strongest predictor). This total test score ranges roughly from 500 to 550. It should be noted that derived test scores that were lower or higher than 500 and 550, respectively, were classified in pro/bb and vwo, i.e., the lowest and highest class respectively.  In this section first the classification errors as a function of the total number of mistakes in Modules A for all six secondary education classes are presented and discussed. Afterwards, based on the same simulation approach, threshold values above (and below) which students tend to be misclassified in a class of secondary education that is not the same as the one that corresponds to their true abilities, are calculated.

```{r echo=FALSE}
Score <- c("501-504", "505-524", "525-532", "533-539", "540-544", "545-550")
Class <- c("pro/bb", "bb/kb", "kb/gt", "gt/havo", "havo/vwo", "vwo")
test_score <- data.frame(Class, Score)
kable(test_score)
```

## Classification errors vs total number of mistakes in modules A

For each of the 1000 replicated MST responses for all 6 typical students the number of mistakes in Module A (for all three sbjects), were calculated using the written `R` scripts used in the first simulation. Afterwards, the 1000 replicates were separated based on the number of mistakes in each subject. It should be noted that not all of the 6 typical students can have all possible combinations of mistakes, for example a typical student for the class pro/bb tends to have mistakes ranging from 16 (6 for Lezen, and 5 for Rekenen and Taal), to around 9. On the other hand, a typical student from vwo tends to have a low total number of mistakes. In the figure below the classification errors as a function of the total number of mistakes in Module A are presented for all 6 classes. A classification error is defined as the proportion of mismatches between the "true" class and the class given based on the scores derived when a student made a certain number of mistakes. Since Shcrijven is administered via a liner test, the "true" ability for this subject will be re-used throughout calculating the classification errors, thus neutralizing the influence of this subject and only observing caused by the subjects administered though an MST.

```{r echo=FALSE, message=FALSE, warning=FALSE, fig.align='center'}
classification.classes.error.modA <- read.csv("errors.data.modA.csv")
classification.classes.error.modA$class <- factor(classification.classes.error.modA$class, 
                                                  levels = c("pro/bb", "bb/kb", "kb/gt", "gt/havo", "havo/vwo", "vwo"), labels = c("pro/bb", "bb/kb", "kb/gt", "gt/havo", "havo/vwo", "vwo"))
classification.classes.error.modA$class <- as.factor(classification.classes.error.modA$class)
ggplot(classification.classes.error.modA, aes(x = mistakes, y = 100 * errors, group = class)) +  
  geom_line(aes(color=class), size = 1)+
  geom_point(aes(color=class)) +
  theme_classic() +
  ylim(0, 30) +
  labs(x = "Total number of mistakes in modules A",
       y = "Classification error (%)")
  
  
```
Starting off with the lowest proficient class pro/bb (red), as the number of total mistakes in Modules A decreases the classification error increases from 3.7% when making 16 mistakes, to 18.6% when making 9 mistakes. A similar situation can be observed with the highest proficient class vwo (purple), there the classification error is 0 when a student makes 0 or 1 mistakes, then slowly increases to 5% when 3 mistakes are made and then sharply to 15% when 6 mistakes are made. An observation that is a cause for optimism is the second class bb/kb (yellow), where the classification error remains zero, while the number of mistakes ranges from 3 to 12. Moving on to the class kb/gt (green), it can be seen that as the number of errors increases from from 1 to 9, the classification error sharply decreases from around 20% to 3%, one can theoretically expect that if the mistakes increase above 12, then the classification error would start to increase again, gaining a parabola-like shape. We can see that we have a similar situation for gt/havo (turquoise) which ranges from 24% when 1 mistake is made, then decreases to 19% and 11% when 3 and 6 mistakes are made, respectively. The same pattern is observed for the class havo/vwo (blue), where the classification error goes from 24% when no mistakes are made than falls to 13% when 3 mistakes are made and then starts to increase again as the number of mistakes increases. These results are also presented in a tabular form in the Appendix.

For the last two observations (gt/havo and havo/vwo), it is evident that the classification errors are higher when compared to the remaining four classes, regardless of the number of mistakes. This can be, in part, explained by the fact that these two classes have the most narrow range of reference test scores (533-539 for gt/havo and 540-544). This is further supported by the bb/kb class, where the range of test scores belonging to a particular class is way wider (505-524), and thus the classification error is practically zero, regardless of the number of mistakes (within rerason of couse, since we can imagine that if the number of mistakes is zero, then some amount of error will be observed).
The main two conclusions that can be drawn from this analysis are:

 - The number of early mistakes do influence the classification in classes of secondary education;
 - There amount of classification error as a function of the number of mistakes varies for the different classes;
 - The amount of classification error for the medium profficient classes is dependant on the respective range of test scores for that particular class, regardless of the number of mistakes.

## Threshold values 

In this last part of the project the aim was focused on deriving certain threshold $\theta$ and consequently reference score values for each subject, above which misclassifications tend to appear for each of the six classes. For the aims of this analysis the same simulated data, as the one in the previous analysis was used. The ability difference between each of the 1000 simulated responses and the typical (true) ability for each of the six classes was calculated, by taking the absolute difference between the true (typical) and the re-estimated ability for each subject. In order to see above which theta difference and reference score value differences appear misclassifcations were calculated for each of the six classes for every subject, while keeping the other two subjects constant (i.e., using their true theta values). The results are presented below for each of the three MST subjcts.

<center> <h3>Lezen</h3> </center>
```{r echo=FALSE}
Class <- c("pro/bb", "bb/kb", "kb/gt", "gt/havo", "havo/vwo", "vwo")
ability.diff <- c(0.18, NA, NA, NA, 0.24, NA)
ref.sc <- c(37, NA, NA, NA, 72, NA)
threshold.Lezen <- data.frame(Class, ability.diff, ref.sc)
names(threshold.Lezen) <- c("Class", "Ability difference", "Reference score")
kable(threshold.Lezen)
```
For Lezen the only classes for which threshold values were found (meaning that classification mismatches were observed), was for pro/bb and havo/wvo.  For pro/bb an absolute discrepancy between the true and the re-estimated ability of 0.18 and higher tends to lead to students being classified in bb/kb, this roughly corresponds to obtaining a score of 37 and higher on the Lezen test. For havo/wvo obtaining an ability discrepancy of 0.24, which corresponds to a  reference score of 72 and higher results in a student being incorrectly slaccisifed to the higher class vwo.

<center> <h3>Rekenen</h3> </center>
```{r echo=FALSE}
ability.diff <- c(0.19, NA, 0.17, 0.19, 0.18, NA)
ref.sc <- c(12, NA, 28, 33, 36, NA)
threshold.Rekenen <- data.frame(Class, ability.diff, ref.sc)
names(threshold.Rekenen) <- c("Class", "Ability difference", "Reference score")
kable(threshold.Rekenen)
```
Rekenen appears to be a bit more sensitive to discrepancies between the true and the estimated abilty, however, as already seen in Simulation 1, these discrepancies are rarely reached compared to the other two subjects. Based on the results, it appears that discrepancies of around 0.18 and above tend to lead to mismatches. Reference scores of 12, 28, 33 and 36 for prob/bb, kb/gt, gt/havo and havo/wvo, respectively should be treated with caution.

<center> <h3>Taal</h3> </center>
```{r echo=FALSE}
ability.diff <- c(0.21, NA, 0.29, NA, 0.37, NA)
ref.sc <- c(28, NA, 59, NA, 44, NA)
threshold.Taal <- data.frame(Class, ability.diff, ref.sc)
names(threshold.Taal) <- c("Class", "Ability difference", "Reference score")
kable(threshold.Taal)
```
 
The highest values of ability discrepancies tend to be present for Taal. Reference score values of 28, 59 and 44 should be treated with caution.

This analysis gives a hint on the average theta discrepancies above which misslassification tend to appear, and it also gives an indication to more carefully observe student with certain reference scores on subjects after they've been classified in a seconday education class. It should be noted however, that this analyis was performed conditional on perfect estimates on the other two subjects, in reality, all three MST's give estimates of the ability and all three (may) containa certain amound of discrepancy, leading to additinal mistmatches. Thus, this analysis fails to capture this important aspect, however it still gives indication of the amount of discepancies on the latent ability that can be tolerated and also gives certain ranges of fererence scores with should be treated with caution while classifying students into secondary education classes. A more general discussion about these results is given in the next section.

<center> <h1>**Conclusion**</h1> </center>

 - Recommendations on the test design
 - Overall conclusions 
 - Improvements for future research 
 
<center> <h1>**References**</h1> </center>

<div id="refs"></div>

\newpage
<center> <h1>**Appendix**</h1> </center>

## Plots

### Mistakes in Module A

```{r echo=FALSE, fig.align = 'center'}
mistakes.modA.lezen.plot <- read.csv("mistakes.modA.lezen.plot.csv")
names(mistakes.modA.lezen.plot) <- c("Re-estimates", "True theta", "Mistakes")
mistakes.modA.lezen.plot$`True theta` <- as.factor(mistakes.modA.lezen.plot$`True theta`)
ggplot(mistakes.modA.lezen.plot[which(mistakes.modA.lezen.plot$`Re-estimates`!=0),], aes(x = Mistakes, y = `Re-estimates`, group = `True theta`)) +  
  geom_line(aes(color=`True theta`), size = 1, linetype = 3)+
  geom_point(aes(color=`True theta`)) +
  theme_classic() +
  ylim(-1.2, 1.6)+ 
  labs(title = "Lezen",
       x = "Number of mistakes in Module A")
```


```{r echo=FALSE, fig.align = 'center'}
mistakes.modA.rekenen.plot <- read.csv("mistakes.modA.rekenen.plot.csv")
names(mistakes.modA.rekenen.plot) <- c("Re-estimates", "True theta", "Mistakes")
mistakes.modA.rekenen.plot$`True theta` <- as.factor(mistakes.modA.rekenen.plot$`True theta`)

ggplot(mistakes.modA.rekenen.plot[which(mistakes.modA.rekenen.plot$`Re-estimates`!=0),], aes(x = Mistakes, y = `Re-estimates`, group = `True theta`)) +  
  geom_line(aes(color=`True theta`), size = 1, linetype = 3)+
  geom_point(aes(color=`True theta`)) +
  theme_classic() +
  ylim(-1.9, 1.9) + 
  labs(title = "Rekenen",
       x = "Number of mistakes in Module A")
```


```{r echo=FALSE, fig.align = 'center'}
mistakes.modA.taal.plot <- read.csv("mistakes.modA.taal.plot.csv")
names(mistakes.modA.taal.plot) <- c("Re-estimates", "True theta", "Mistakes")
mistakes.modA.taal.plot$`True theta` <- as.factor(mistakes.modA.taal.plot$`True theta`)

ggplot(mistakes.modA.taal.plot[which(mistakes.modA.taal.plot$`Re-estimates`!=0),], aes(x = Mistakes, y = `Re-estimates`, group = `True theta`)) +  
  geom_line(aes(color=`True theta`), size = 1, linetype = 3)+
  theme_classic() +
  geom_point(aes(color=`True theta`)) +
  ylim(-1.9, 1.9)+ 
  labs(title = "Taal",
       x = "Number of mistakes in Module A")
```



```{r echo=FALSE, message=FALSE, warning=FALSE, fig.align = 'center'}
data <- read_sav("experiment_data.sav")
data$subject <- as.factor(data$subject)
scatter <- ggplot(data, aes(avg.error.modA, log10(avg.theta.diff), colour=subject))  
A <- scatter + geom_point() + geom_smooth(method=lm, se=FALSE, fullrange=TRUE) +
   theme_classic() + theme(legend.position="none") + 
  labs(y = "Log Avg. theta difference", "Avg. errors in Module A")

# For average mistakes in day 1
scatter <- ggplot(data, aes(avg.error.Day1, log10(avg.theta.diff), colour=subject))  
B <- scatter + geom_point() + geom_smooth(method=lm, se=FALSE, fullrange=TRUE) + 
  theme_classic() + theme(legend.position="") + 
  labs(y = "Log Avg. theta difference", "Avg. errors in Day 1")

# For number of paths
scatter <- ggplot(data, aes(n.paths, log10(avg.theta.diff), colour=subject))  
C <- scatter + geom_point() + geom_smooth(method=lm, se=FALSE, fullrange=TRUE) +
  theme_classic() + 
  labs(y = "Log Avg. theta difference", x = "Number of paths")

#Combine
ggarrange(A, B, C,
          labels = c("", "", ""),
          ncol = 2, nrow = 2)
```

## Linear function for the total ACET test score


$$Total\ score = 484.75816 + Lezen * 0.234368499 + Taal * 0.232847623 + Rekenen * 0.706118502 + schrijven * 0.127383676$$

## Classification errors and total number of mistakes in modules A
```{r echo=FALSE}
classification.classes.error.modA <- classification.classes.error.modA[, - 1]
kable(classification.classes.error.modA, digits = 2)
```

